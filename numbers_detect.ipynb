{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число слоев  3\n",
      "Число нейронов в слое  0 :  2\n",
      "Число нейронов в слое  1 :  3\n",
      "Число нейронов в слое  2 :  1\n",
      "w  1 : [[ 0.95  0.16]\n",
      " [ 0.17  0.01]\n",
      " [-1.2  -0.28]]\n",
      "b  1 : [[ 0.95  0.16]\n",
      " [ 0.17  0.01]\n",
      " [-1.2  -0.28]]\n",
      "w  2 : [[-0.16  0.02 -2.51]]\n",
      "b  2 : [[-0.16  0.02 -2.51]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0+np.exp(-x))\n",
    "\n",
    "\n",
    "# производная сигмодидальной функции\n",
    "def sigmoid_pr(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        \n",
    "        # Задаём начальные смещения\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        \n",
    "        # Указаны начальные веса: в sizes указывается \n",
    "        # 1) количество элементов входного слоя, 2) количество элементов внутреннего слоя, \n",
    "        # 3) кол-во элеметов выходного слоя        \n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "    \n",
    "    # Возвращает результат работы нейросети\n",
    "    def feedforward(self, a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    # Обучение нейросети\n",
    "    def SGD(self, train, epochs, minibatch_size, eta, test):\n",
    "        test =  list(test)\n",
    "        len_test = len(test)\n",
    "        train = list(train)\n",
    "        len_train = len(train)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            random.shuffle(train)\n",
    "            # создание листа из подвыборок из train\n",
    "            mini_batches = [train[k:k+minibatch_size] for k in range(0, len_train, minibatch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                # один шаг градиентного спуска\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            print(i, \" \", self.evaluate(test), len_test)\n",
    "                \n",
    "                \n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        # список градиентов для каждого слоя\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            d_nablab, d_nablaw = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, d_nablab)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, d_nablaw)]\n",
    "            self.weights = [w - (eta/len(mini_batch))*nw for w, nw in zip(self.weights, nabla_w)]\n",
    "            self.biases = [b - (eta/len(mini_batch))*nb for b, nb in zip(self.biases, nabla_b)]\n",
    "            \n",
    "    \n",
    "    def backprop(self, X, y):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        activation = X\n",
    "        activations = [X]\n",
    "        zs = []\n",
    "        \n",
    "        # прямое распространение\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        \n",
    "        # обратное распространение\n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_pr(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        for i in range(2, self.num_layers):\n",
    "            z = zs[-i]\n",
    "            sp = sigmoid_pr(z)\n",
    "            delta = np.dot(self.weights[-i+1].transpose(), delta) * sp\n",
    "            nabla_b[-i] = delta\n",
    "            nabla_w[-i] = np.dot(delta, activations[-i-1].transpose())\n",
    "        return nabla_b, nabla_w\n",
    "    \n",
    "    # количество правильных результатов работы нейросети  \n",
    "    def evaluate(self, test):\n",
    "        # test_result[0] - вектор с изображением цифры\n",
    "        # test_result[1] - значение цифры на картинке\n",
    "        # Ответ нейросети - номер нейрона в выходном слое, имеющего \n",
    "        # наибольшее значение функции активации\n",
    "        test_results = [(np.argmax(self.feedforward(X)), y) for (X, y) in test]\n",
    "        return sum(int(X==y) for (X, y) in test_results)\n",
    "    \n",
    "    # считает вектор частных производных в градиенте\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        return output_activations - y\n",
    "                \n",
    "    \n",
    "        \n",
    "        \n",
    "net = Network([2, 3, 1])\n",
    "print('Число слоев ', net.num_layers)\n",
    "for i in range(net.num_layers):\n",
    "    print('Число нейронов в слое ', i, ': ', net.sizes[i])\n",
    "for i in range(net.num_layers-1):\n",
    "    print('w ', i+1, ':', np.round(net.weights[i], 2))\n",
    "    print('b ', i+1, ':', np.round(net.weights[i], 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "    train_data, valid_data, test_data = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    return (train_data, valid_data, test_data)\n",
    "\n",
    "# преобразование train в список из 50000 пар (X, y) (Признаки - метки)\n",
    "def load_data_wrapper():\n",
    "    train, valid, test = load_data()\n",
    "    train_input = [np.reshape(X, (784, 1)) for X in train[0]]\n",
    "    train_result = [vectorized_result(y) for y in train[1]]\n",
    "    train_data = zip(train_input, train_result)\n",
    "    \n",
    "    valid_input = [np.reshape(X, (784, 1)) for X in valid[0]]\n",
    "    valid_data = zip(valid_input, valid[1])\n",
    "    \n",
    "    test_input = [np.reshape(X, (784, 1)) for X in test[0]]\n",
    "    test_data = zip(test_input, test[1])\n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "\n",
    "def vectorized_result(i):\n",
    "    e = np.zeros((10, 1))\n",
    "    e[i] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   7894 10000\n",
      "1   7968 10000\n",
      "2   8564 10000\n",
      "3   8839 10000\n",
      "4   8982 10000\n",
      "5   8964 10000\n",
      "6   9004 10000\n",
      "7   9028 10000\n",
      "8   9094 10000\n",
      "9   9014 10000\n",
      "10   9083 10000\n",
      "11   9020 10000\n",
      "12   9130 10000\n",
      "13   9208 10000\n",
      "14   9156 10000\n",
      "15   9148 10000\n",
      "16   9199 10000\n",
      "17   9163 10000\n",
      "18   9194 10000\n",
      "19   9162 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-95f6603b3faf>:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0+np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20   9117 10000\n",
      "21   9187 10000\n",
      "22   9056 10000\n",
      "23   9197 10000\n",
      "24   9101 10000\n",
      "25   9176 10000\n",
      "26   9195 10000\n",
      "27   9134 10000\n",
      "28   9228 10000\n",
      "29   9263 10000\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = load_data_wrapper()\n",
    "net = Network([784, 30, 10])\n",
    "net.SGD(train, 30, 10, 3.0, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
